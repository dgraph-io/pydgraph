{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtVJnO3SzTgt"
      },
      "source": [
        "See DemoSetupREADME.md for configuration instructions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_qEDD3UC7uqF",
        "outputId": "7ac814f4-49b8-4e08-a3a3-888d4e604a52"
      },
      "outputs": [],
      "source": [
        "%pip install pydgraph python-graphql-client ipycytoscape qdrant_client\n",
        "import pydgraph\n",
        "import json\n",
        "import base64\n",
        "import getpass\n",
        "from python_graphql_client import GraphqlClient\n",
        "from qdrant_client import QdrantClient\n",
        "# Load configuration from user-specific file\n",
        "config_file = \"config-local.json\"  # Name of the user-specific configuration file\n",
        "with open(config_file, \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Extract values from the configuration\n",
        "dgraph_cerebro = config[\"dgraph_cerebro\"]\n",
        "dgraph_graphql_endpoint = config[\"dgraph_graphql_endpoint\"]\n",
        "dgraph_grpc = config[\"dgraph_grpc\"]\n",
        "qdrnt_endpoint = config[\"qdrnt_endpoint\"]\n",
        "qdrnt_collection = config[\"qdrnt_collection\"]\n",
        "qdrnt_api_key = config[\"qdrnt_api_key\"]\n",
        "dgraph_cloud_user = config[\"dgraph_cloud_user\"]\n",
        "dgraph_cloud_passw = config[\"dgraph_cloud_passw\"]\n",
        "APIAdminKey = config[\"APIAdminKey\"]\n",
        "\n",
        "OpenAIKey = config[\"OpenAIKey\"]# the host or IP addr where your Dgraph alpha service is running\n",
        "\n",
        "\n",
        "\n",
        "# graph admin endpoint is /admin\n",
        "dgraph_graphql_admin = dgraph_graphql_endpoint.replace(\"/graphql\", \"/admin\")\n",
        "print(dgraph_graphql_admin)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0HkbitRJm3_8"
      },
      "source": [
        "\n",
        "\n",
        "# Enter credentials and set up db client objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "E7EvVHCqXzfV",
        "outputId": "a72ecfd6-1570-4579-cf68-b382aaa3bef6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cloud credentials\n",
        "# we need the cloud login credential to upload the Lambda code.\n",
        "# we need the an Admin API key generated at https://cloud.dgraph.io/_/settings?tab=api-keys for DQL alter and query\n",
        "\n",
        "\n",
        "\n",
        "# DQL Client\n",
        "client_stub = pydgraph.DgraphClientStub.from_cloud(dgraph_grpc,APIAdminKey )\n",
        "client = pydgraph.DgraphClient(client_stub)\n",
        "\n",
        "\n",
        "# GraphQL client and admin client\n",
        "gql_client = GraphqlClient(endpoint=dgraph_graphql_endpoint)\n",
        "headers = { \"Dg-Auth\": APIAdminKey }\n",
        "gql_admin_client = GraphqlClient(endpoint=dgraph_graphql_admin, headers=headers)\n",
        "gql_cloud_client = GraphqlClient(endpoint=dgraph_cerebro)\n",
        "\n",
        "print(\"graphql client connections/objects established\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VUDLb8rs8pQZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Verifying cluster health and delete all data including GraphQL schema\n",
        "#\n",
        "data = gql_admin_client.execute(query=\"{health {instance version status}}\")\n",
        "if 'errors' in data:\n",
        "   raise Exception(data['errors'][0]['message'])\n",
        "\n",
        "\n",
        "print(\"generic graphql client, check cluster health:\", json.dumps(data, indent=2))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tdDmK09BnFUd"
      },
      "source": [
        "# Clear old data and load schema and new data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ZeR3IxXzauQ6"
      },
      "outputs": [],
      "source": [
        "# TODO: add drop all permissions\n",
        "# for now: drop data using cloud GUI shcema > drop all button\n",
        "\n",
        "#Drop all data including schema from the Dgraph instance. This is a useful\n",
        "# for small examples such as this since it puts Dgraph into a clean state.\n",
        "\n",
        "#TODO: Do this from Dgraph Cloud Schema tab. Hit Drop data, then drop all data to clean the dgraph db.\n",
        "confirm = input(\"drop schema and all data (y/n)?\")\n",
        "if confirm == \"y\":\n",
        "  op = pydgraph.Operation(drop_all=True)\n",
        "  client.alter(op)\n",
        "  print(\"schema and data deleted\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K7WJ92ZXlb7l",
        "outputId": "48682295-b35b-43c0-904f-4401db9817c5"
      },
      "outputs": [],
      "source": [
        "# Deploy the GraphQL Schema\n",
        "\n",
        "graphql_schema = \"\"\"\n",
        "type Equipment {\n",
        "  id: ID!\n",
        "  name: String! @search(by: [term])\n",
        "  model: EquipmentModel\n",
        "  sensorData: [SensorData] @hasInverse(field: equipment)\n",
        "  oilRig: OilRig @hasInverse(field: equipment)\n",
        "}\n",
        "\n",
        "type EquipmentModel {\n",
        "  id: ID!\n",
        "  model: String!\n",
        "  installed: [Equipment] @hasInverse(field: model)\n",
        "}\n",
        "\n",
        "type SensorData @lambdaOnMutate(add: true, update: false, delete: false) {\n",
        "  id: ID!\n",
        "  timestamp: DateTime!\n",
        "  value: Float!\n",
        "  equipment: Equipment! @hasInverse(field: sensorData)\n",
        "  embeddings: [Float!] @lambda\n",
        "}\n",
        "\n",
        "type OilRig @lambdaOnMutate(add: true, update: false, delete: false) {\n",
        "  id: ID!\n",
        "  name: String! @search(by: [fulltext, exact])\n",
        "  equipment: [Equipment!]! @hasInverse(field: oilRig)\n",
        "  issues: [Issue] @hasInverse(field: oilRig)\n",
        "}\n",
        "\n",
        "type Issue @lambdaOnMutate(add: true, update: false, delete: false) {\n",
        "  id: ID!\n",
        "  name: String!\n",
        "  description: String!\n",
        "  embeddings: [Float!] @lambda\n",
        "  solution: String!\n",
        "  equipment: [Equipment]\n",
        "  oilRig: OilRig! @hasInverse(field: issues)\n",
        "  similarIssues: [Issue] @lambda\n",
        "  score: Float\n",
        "}\n",
        "\n",
        "type Expert {\n",
        "  id: ID!\n",
        "  name: String!\n",
        "  expertise: [String!] @search(by: [term])\n",
        "}\n",
        "\n",
        "type Query {\n",
        "  getSimilarIssues(description: String!, first: Int!): [Issue] @lambda\n",
        "  getSimilarIssuesById(uid: String!, first: Int!): [Issue] @lambda\n",
        "  getRelevantExperts(issueName: String!): [Expert] @lambda\n",
        "}\n",
        "\n",
        "input OilRigInput {\n",
        "  name: String!\n",
        "  equipment: [EquipmentInput!]\n",
        "}\n",
        "\n",
        "input EquipmentInput {\n",
        "  name: String!\n",
        "  sensorData: [SensorDataInput!]\n",
        "}\n",
        "\n",
        "input SensorDataInput {\n",
        "  timestamp: DateTime!\n",
        "  value: Float!\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mutation = \"\"\"\n",
        "mutation($sch: String!) {\n",
        "  updateGQLSchema(input: { set: { schema: $sch}})\n",
        "  {\n",
        "    gqlSchema {\n",
        "      schema\n",
        "      generatedSchema\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "variables = {\"sch\": graphql_schema}\n",
        "schemadata = gql_admin_client.execute(query=mutation, variables=variables)\n",
        "print(\"GraphQL Schema after Update\")\n",
        "print(schemadata)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "VCb4Ym7ZCdcN",
        "outputId": "56bd05ce-6f70-4ef8-dddd-70179c71b39b"
      },
      "outputs": [],
      "source": [
        "# shared equipment\n",
        "\n",
        "addEquipmentModel = \"\"\"\n",
        "mutation MyMutation($input: [AddEquipmentModelInput!]!) {\n",
        "  response: addEquipmentModel(input: $input) {\n",
        "     equipmentModel {id}\n",
        "  }\n",
        "  }\n",
        "\"\"\"\n",
        "equip_model_data = [\n",
        "    {\n",
        "        \"input\":\n",
        "          {\"model\": \"Acme Pumps WHC-92\"}\n",
        "    }\n",
        "]\n",
        "\n",
        "# Run the mutation\n",
        "for em in equip_model_data:\n",
        "    print(em)\n",
        "    result = gql_client.execute(addEquipmentModel, variables={\"input\": em[\"input\"]})\n",
        "    print(\"result=\", result)\n",
        "    compressorId = result['data']['response']['equipmentModel'][0]['id']\n",
        "    print(\"wellhead id=\"+compressorId)\n",
        "\n",
        "\n",
        "\n",
        "addWellheadCompressor = \"\"\"\n",
        "mutation MyMutation($input: [AddEquipmentInput!]!) {\n",
        "  response: addEquipment(input: $input) {\n",
        "      equipment { name id }\n",
        "    }\n",
        "  }\n",
        "\"\"\"\n",
        "equip_data = [\n",
        "    {\n",
        "    \"input\": [\n",
        "      {\"name\": \"Wellhead Compressor\",\n",
        "        \"model\": {\n",
        "          \"id\": compressorId\n",
        "        }},\n",
        "      {\"name\": \"Wellhead Booster\",\n",
        "        \"model\": {\n",
        "          \"id\": compressorId\n",
        "        }},\n",
        "    ]\n",
        "    },\n",
        "]\n",
        "\n",
        "# Run the mutation\n",
        "for e in equip_data:\n",
        "    print(e)\n",
        "    result = gql_client.execute(addWellheadCompressor, variables={\"input\": e[\"input\"]})\n",
        "    print(result)\n",
        "    wellheadCompressorId = result['data']['response']['equipment'][0]['id']\n",
        "    wellheadBoosterId = result['data']['response']['equipment'][1]['id']\n",
        "    print(\"wellhead id=\"+wellheadCompressorId)\n",
        "    print(\"pump id=\"+wellheadBoosterId)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOnVjxaArHZL",
        "outputId": "017bfe26-71e9-4265-9eb6-95aa248918be"
      },
      "outputs": [],
      "source": [
        "# Oil rigs\n",
        "addOilRigRaph = \"\"\"\n",
        "mutation MyMutation($input: [AddOilRigInput!]!) {\n",
        "  response: addOilRig(input: $input) {\n",
        "    oilRig {\n",
        "      id\n",
        "      equipment { name id }\n",
        "      issues {\n",
        "        id\n",
        "        equipment { name id }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "oil_rig_data =   [\n",
        "    {\n",
        "        \"input\": {\n",
        "            \"name\": \"Ocean Driller 1\",\n",
        "            \"equipment\": [\n",
        "                {\n",
        "                    \"name\": \"Downhole drilling motor A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill bit A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill stabilizer A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Downhole Pump A\"\n",
        "                }\n",
        "            ],\n",
        "            \"issues\": [\n",
        "                {\n",
        "                    \"name\": \"Mud Gate Valve leak\",\n",
        "                    \"description\": \"Primary mud gate valve leaking slightly. 3 inch valve leaking below bonnet. Stopped drilling and replaced bonnet seal.\",\n",
        "                    \"solution\": \"Tightened valve connection\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": {\n",
        "            \"name\": \"Ocean Driller 2\",\n",
        "            \"equipment\": [\n",
        "                {\n",
        "                    \"name\": \"Downhole drilling motor A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill bit A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill stabilizer A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Downhole Pump A\"\n",
        "                }\n",
        "            ],\n",
        "            \"issues\": [\n",
        "              {\n",
        "                \"name\": \"Shale vibration issue\",\n",
        "                \"description\": \"Vibration detected coupled with slowly rising temperature readings while drilling through light shale layer at depth of 1700 meters. Downhole bore assembly recently inspected and unlikely to be at issue.\",\n",
        "                \"solution\": \"\"\n",
        "              }\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": {\n",
        "            \"name\": \"West Texas ND-3\",\n",
        "            \"equipment\": [\n",
        "                {\n",
        "                    \"name\": \"Downhole drilling motor B\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill bit A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill stabilizer A\"\n",
        "                },\n",
        "                {\n",
        "                    \"id\": wellheadCompressorId,\n",
        "                    \"name\": \"Wellhead Compressor\",\n",
        "                    \"model\": {\n",
        "                        \"model\": \"Acme Booster Compressor 3000\"\n",
        "                    }\n",
        "                }\n",
        "            ],\n",
        "            \"issues\": [\n",
        "              {\n",
        "                  \"name\": \"Wellhead compressor vibration\",\n",
        "                  \"description\": \"Wellhead compressor rattling. Probably earlier liquid slug hit due to report of overnight banging Temperature remaining low - no changes since banging. Inspection showed some bearing wear previously.\",\n",
        "                  \"solution\": \"Ordered new compressor bearings. Reduced pressure and switched to oil-based mud for the short term to reduce load on compressor.\",\n",
        "                  \"equipment\": [{\"id\": wellheadCompressorId}]\n",
        "              }\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": {\n",
        "            \"name\": \"West Texas ND-4\",\n",
        "            \"equipment\": [\n",
        "                {\n",
        "                    \"name\": \"Booster compressor\",\n",
        "                    \"id\": wellheadBoosterId\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill bit B\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill stabilizer A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Downhole Pump A\"\n",
        "                }\n",
        "            ],\n",
        "            \"issues\": [\n",
        "              {\n",
        "                \"name\": \"Reduced pressure\",\n",
        "                \"description\": \"Wellhead compressor may be failing - lower pressure and higher temperature observed (230psi vs expected 300psi, and temperature rising to 230+ degrees on hot days.\",\n",
        "                \"solution\": \"Pumped Oil-based mud (OBM) into the borehole. Moderate mud weight of 14 pounds per gallong (ppg) used to avoid cavitation. Scheduled service of the pump to determine root cause.\",\n",
        "                \"equipment\": [{\"id\": wellheadBoosterId}]\n",
        "              }\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": {\n",
        "            \"name\": \"Ocean Driller 5\",\n",
        "            \"equipment\": [\n",
        "                {\n",
        "                    \"name\": \"Downhole drilling motor A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill bit B\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Drill stabilizer A\"\n",
        "                },\n",
        "                {\n",
        "                    \"name\": \"Booster Compressor (TODO: equip)\"\n",
        "                }\n",
        "            ],\n",
        "            \"issues\": [\n",
        "              {\n",
        "                \"name\": \"Drill hot\",\n",
        "                \"description\": \"Drill collar overheating, requiring drill slowdown. Suspect an issue with mud volume, or low pressure due to failing booster pump. There was a slug hit on the compressor last week, making the pump\",\n",
        "                \"solution\": \"Pumped Oil-based mud (OBM) into the borehole. Moderate mud weight of 14 pounds per gallong (ppg) used to avoid cavitation.\"\n",
        "              }\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Run the mutation\n",
        "for rig in oil_rig_data:\n",
        "    print(rig)\n",
        "    result = gql_client.execute(addOilRigRaph, variables={\"input\": rig[\"input\"]})\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TukK0PyetGIA"
      },
      "outputs": [],
      "source": [
        "addExpert = \"\"\"\n",
        "mutation NewExpertMutation($name: String!, $expertise: [String!]!) {\n",
        "    addExpert(input: {name: $name, expertise: $expertise}) {\n",
        "        expert {\n",
        "            id\n",
        "        }\n",
        "    }\n",
        "}\"\"\"\n",
        "# Experts\n",
        "expert_data = [\n",
        "    {\n",
        "        \"name\": \"Dr. James Bond\",\n",
        "        \"expertise\": [\"Downhole pump systems, including collar, bits, and mud pumps\", \"Pump repair and diagnosis\", \"Temperature, pressure and vibration monitoring\"]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Prof. Maria Hill\",\n",
        "        \"expertise\": [\"Valve sizing and monitoring\", \"Fluid dynamics\", \"Flow rate disruptions or slowdown\", \"Cavitation detection and remediation\"]\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Mr. Tony Stark\",\n",
        "        \"expertise\": [\"Motor mechanisms\", \"Motor overheating, overload, lubrication and cooling issues\", \"Geochemistry and rock formations\", \"Stick-slip detection and rebalancing\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "expert_ids = []\n",
        "for expert in expert_data:\n",
        "    variables = {\"name\": expert[\"name\"], \"expertise\": expert[\"expertise\"]}\n",
        "    result = gql_client.execute(query=addExpert, variables=variables)\n",
        "    expert_ids.append(result['data']['addExpert']['expert'][0]['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "EMxiwuU_tOZI",
        "outputId": "524337a7-153b-4aba-9199-b2edc6ac7616"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Assuming we don't need this in the approach where the equipment is nested items under the Oil Rig in above mutation\n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "addEquipment = \"\"\"\n",
        "mutation NewEquipmentMutation($name: String!) {\n",
        "    addEquipment(input: {name: $name}) {\n",
        "        equipment {\n",
        "            id\n",
        "        }\n",
        "    }\n",
        "}\"\"\"\n",
        "equipment_data = [\n",
        "    {\n",
        "        \"name\": \"Pump A\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Motor B\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Valve C\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Equipment\n",
        "equipment_ids = []\n",
        "for equipment in equipment_data:\n",
        "    variables = {\"name\": equipment[\"name\"]}\n",
        "    result = gql_client.execute(query=addEquipment, variables=variables)\n",
        "    equipment_ids.append(result['data']['addEquipment']['equipment'][0]['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZQAFYymti5S"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Assuming we don't need this in the approach where the sensor data is nested items under the Oil Rig in above mutation\n",
        "#\n",
        "#\n",
        "\n",
        "\n",
        "addSensorData = \"\"\"\n",
        "mutation NewSensorDataMutation($timestamp: DateTime!, $value: Float!, $equipmentID: ID!) {\n",
        "    addSensorData(input: {timestamp: $timestamp, value: $value, equipment: {id: $equipmentID}}) {\n",
        "        sensorData {\n",
        "            id\n",
        "        }\n",
        "    }\n",
        "}\"\"\"\n",
        "sensor_data = [\n",
        "    {\n",
        "        \"timestamp\": \"2023-06-24T18:25:43.511Z\",\n",
        "        \"value\": 10.5\n",
        "    },\n",
        "    {\n",
        "        \"timestamp\": \"2023-06-20T13:15:30.789Z\",\n",
        "        \"value\": 30.2\n",
        "    },\n",
        "    {\n",
        "        \"timestamp\": \"2023-06-19T09:05:21.654Z\",\n",
        "        \"value\": 50.1\n",
        "    }\n",
        "]\n",
        "# Sensor data\n",
        "for i, data in enumerate(sensor_data):\n",
        "    variables = {\"timestamp\": data[\"timestamp\"], \"value\": data[\"value\"], \"equipmentID\": equipment_ids[i]}\n",
        "    gql_client.execute(query=addSensorData, variables=variables)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "r0er6HONAjr9",
        "outputId": "920a174c-5be1-49ff-a73f-48ea4ff2854c"
      },
      "outputs": [],
      "source": [
        "# Issues are now part of the overall Oil Rig data above\n",
        "# Skip this.\n",
        "#\n",
        "\n",
        "\n",
        "#Create Issues\n",
        "addIssue = \"\"\"\n",
        "mutation NewIssueMutation($name: String!, $description: String!, $solution: String!) {\n",
        "    addIssue(input: {name: $name, description: $description, solution: $solution}) {\n",
        "        numUids\n",
        "    }\n",
        "}\"\"\"\n",
        "exampleIssue = \"\"\"\n",
        "mutation MyMutation {\n",
        "  addIssue(input: {\n",
        "      name: \"Shale vibration issue\",\n",
        "      description: \"Vibration detected coupled with slowly rising temperature readings while drilling through light shale layer at depth of 230 meters. Downhole bore assembly recently inspected and unlikely to be at issue.\",\n",
        "      solution: \"\",\n",
        "      oilRig: {id: \"0xfffd8d7286de7b9e\"}}) {\n",
        "    issue {\n",
        "      id\n",
        "      name\n",
        "      oilRig {\n",
        "        name\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "issues_data = [\n",
        "    {\"name\": \"Mud pump hammering\", \"equipment\":\"Pump 1\",\n",
        "       \"description\": \"Hammering noise from piples and pump area when using heavy mud (18 ppg). Vibration sensors downwell suggest some cavitation. Pressure fluctuating +/- 20 psi during hammer noise incidents, but pump pressure remaiing over 200psi.\",\n",
        "       \"solution\": \"Replaced pump filter\"},\n",
        "    {\"name\": \"Drill \",\n",
        "       \"description\": \"Drill collar overheating\",\n",
        "       \"solution\": \"Pumped Oil-based mud (OBM) into the borehole. Moderate mud weight of 14 pounds per gallong (ppg) used to avoid cavitation.\"},\n",
        "    {\"name\": \"Wellhead compressor noise\",\n",
        "       \"description\": \"Wellhead compressor noise on hot days (starting around temperature over 35 degrees C)\",\n",
        "       \"solution\": \"Ordered new compressor bearings. Reduced pressure and switched to oil-based mud for the short term to reduce load on compressor.\"},\n",
        "    {\"name\": \"Mud Gate Valve leak\",\n",
        "       \"description\": \"Primary mud gate valve leaking slightly. 3 inch valve leaking below bonnet. Stopped drilling and replaced bonnet seal.\",\n",
        "       \"solution\": \"Tightened valve connection\"},\n",
        "]\n",
        "\n",
        "for issue in issues_data:\n",
        "    gql_client.execute(query=addIssue, variables=issue)\n",
        "\n",
        "print(\"Issues created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5472kylIAmFC"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Are these used?\n",
        "#\n",
        "#\n",
        "\n",
        "# Create Status Updates\n",
        "addStatusUpdate = \"\"\"\n",
        "mutation NewStatusUpdateMutation($time: DateTime!, $description: String!) {\n",
        "    addStatusUpdate(input: {time: $time, description: $description}) {\n",
        "        numUids\n",
        "    }\n",
        "}\"\"\"\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "time_now = datetime.now()\n",
        "status_updates_data = [\n",
        "    {\"time\": time_now.isoformat(), \"description\": \"Pump A making strange noise\"},\n",
        "    {\"time\": (time_now - timedelta(days=1)).isoformat(), \"description\": \"Drill B overheating\"},\n",
        "    {\"time\": (time_now - timedelta(days=2)).isoformat(), \"description\": \"Compressor C not starting\"},\n",
        "    {\"time\": (time_now - timedelta(days=3)).isoformat(), \"description\": \"Valve D leaking\"},\n",
        "]\n",
        "\n",
        "for update in status_updates_data:\n",
        "    gql_client.execute(query=addStatusUpdate, variables=update)\n",
        "\n",
        "print(\"Status updates created\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cI4rI2Ofnc9U"
      },
      "source": [
        "# Add JS hooks (lambda functions) to call LLM + Vector DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OXmFvQe0rlDW",
        "outputId": "12b84c54-2e81-46db-830e-0b4509d2244c"
      },
      "outputs": [],
      "source": [
        "# Get a token to be able to change the database\n",
        "# Lambda is deployed through Cloud Cerebro endpoint, and needs a token\n",
        "\n",
        "login = \"\"\"\n",
        "query  login($email: String!, $passw: String!){\n",
        "  login(email: $email, password: $passw) {\n",
        "    token\n",
        "  }\n",
        "}\n",
        "\"\"\"\n",
        "login_var = { \"email\": dgraph_cloud_user, \"passw\": dgraph_cloud_passw}\n",
        "login_info = gql_cloud_client.execute(query=login, variables=login_var)\n",
        "\n",
        "token = login_info['data']['login']['token']\n",
        "cerebro_headers = { \"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \"+token }\n",
        "\n",
        "print(\"Cerebro token retrieved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XeaFJyVJ8LlE",
        "outputId": "e70ca47a-a972-4f98-90cd-c42de9031f44"
      },
      "outputs": [],
      "source": [
        "# We need to get the lambda deployment ID for the GraphQL endpoint\n",
        "# note the double curly brackets to use format!\n",
        "query = \"\"\"\n",
        "query {{\n",
        "    searchDeployments(inputType: endpoint, searchText: \"{0}\") {{\n",
        "        subdomain\n",
        "        name\n",
        "        uid\n",
        "    }}\n",
        "}}\n",
        "\"\"\".format(dgraph_graphql_endpoint)\n",
        "\n",
        "deployment_info = gql_cloud_client.execute(query=query, headers=cerebro_headers)\n",
        "print(json.dumps(deployment_info, indent=2))\n",
        "deploymentID = deployment_info['data']['searchDeployments'][0]['uid']\n",
        "\n",
        "print('DeploymentID: '+deploymentID)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0fKbqP4_y23Y"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "73sXFYcNCDqa",
        "outputId": "224c2a96-1b47-463b-cdce-6ff66bb5101c"
      },
      "outputs": [],
      "source": [
        "script = \"\"\"\n",
        "function dotProduct(v,w) {\n",
        "   return v.reduce((l,r,i)=>l+r*w[i],0)\n",
        "   // as openapi embedding vectors are normalized\n",
        "   // dot product = cosine similarity\n",
        "}\n",
        "\n",
        "async function saveVector(nodetype,uid,vec) {\n",
        "  try {\n",
        "  let url = `\"\"\"+qdrnt_endpoint+\"\"\"/collections/\"\"\"+qdrnt_collection+\"\"\"/points?wait=true`;\n",
        "  let body = `{ \"points\": [ { \"id\":${BigInt(uid).toString()}, \"vector\":[${vec}], \"payload\": { \"type\": \"${nodetype}\"} } ] }`\n",
        "  let response = await fetch(url,{\n",
        "    method: \"PUT\",\n",
        "    headers: {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"api-key\": `\"\"\"+qdrnt_api_key+\"\"\"`\n",
        "    },\n",
        "    body: body\n",
        "  })\n",
        "\n",
        "  let data = await response.text();\n",
        "  } catch (error) {\n",
        "    console.log(\"Error during saveVector: \"+ error)\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "async function searchSimilarity(ID, vec,nodetype,limit=10) {\n",
        "  try {\n",
        "  let url = `\"\"\"+qdrnt_endpoint+\"\"\"/collections/\"\"\"+qdrnt_collection+\"\"\"/points/search?wait=true`;\n",
        "  let body = `{\n",
        "    \"vector\" : [${vec}],\n",
        "    \"filter\" : {\n",
        "            \"must\" : [ {\n",
        "                \"key\":\"type\",\n",
        "                \"match\": {\n",
        "                    \"value\":\"${nodetype}\"\n",
        "                }\n",
        "            }],\n",
        "            \"must_not\": [{\"has_id\":[${ID}]}]\n",
        "        },\n",
        "    \"limit\":${limit}\n",
        "    }`\n",
        "    let response = await fetch(url,{\n",
        "    method: \"POST\",\n",
        "    headers: {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"api-key\": `\"\"\"+qdrnt_api_key+\"\"\"`\n",
        "    },\n",
        "    body: body\n",
        "  })\n",
        "  console.log(\"qdrant response status: \"+ response.status);\n",
        "    let resp = await response.text()\n",
        "    let r1 = /\"id\":(?<id>\\d+)/g\n",
        "    let r2 = /\"score\":(?<score>\\d*.\\d*)/g\n",
        "    data = []\n",
        "    while ((m=r1.exec(resp)) != null) {\n",
        "      data.push( {\n",
        "        \"id\":m.groups['id']\n",
        "      })\n",
        "    }\n",
        "    let i = 0\n",
        "    while ((m=r2.exec(resp)) != null) {\n",
        "      data[i][\"score\"]=m.groups['score']\n",
        "      i++\n",
        "    }\n",
        "    if (response.status == 400) {\n",
        "      console.log(\"Error 400 from qdrant: \"+resp)\n",
        "    }\n",
        "    return data // array with id and score\n",
        "    } catch (error) {\n",
        "      console.log(\"Error getting qdrant response: \"+ error)\n",
        "    }\n",
        "}\n",
        "async function searchSimilarityByID(ID,nodetype,limit=10) {\n",
        "  try {\n",
        "  let url = `\"\"\"+qdrnt_endpoint+\"\"\"/collections/\"\"\"+qdrnt_collection+\"\"\"/points/`+ID;\n",
        "  console.log(url)\n",
        "    let response = await fetch(url,{\n",
        "    method: \"GET\",\n",
        "    headers: {\n",
        "      \"api-key\": `\"\"\"+qdrnt_api_key+\"\"\"`\n",
        "    },\n",
        "  })\n",
        "  console.log(\"qdrant response status: \"+ response.status);\n",
        "  const data = await response.json();\n",
        "\n",
        "  const vector = data.result.vector;\n",
        "  const issues = await searchSimilarity(ID,vector, \"Issue\", limit);\n",
        "  return issues\n",
        "  } catch (error) {\n",
        "      console.log(\"Error getting qdrant response: \"+ error)\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "async function mutateRDF(dql,rdfs) {\n",
        "  console.log(\"Mutation: \" + rdfs)\n",
        "  if (rdfs !== \"\") {\n",
        "        return dql.mutate(`{\n",
        "                set {\n",
        "                    ${rdfs}\n",
        "                }\n",
        "            }`)\n",
        "    }\n",
        "}\n",
        "\n",
        "async function mutateRDF(dql,rdfs) {\n",
        "  console.log(\"Mutation: \" + rdfs)\n",
        "  if (rdfs !== \"\") {\n",
        "        return dql.mutate(`{\n",
        "                set {\n",
        "                    ${rdfs}\n",
        "                }\n",
        "            }`)\n",
        "    }\n",
        "}\n",
        "\n",
        "async function embedding(text) {\n",
        "  console.log(\"getting embedding vector for: \"+text)\n",
        "  let url = `https://api.openai.com/v1/embeddings`;\n",
        "  let response = await fetch(url,{\n",
        "    method: \"POST\",\n",
        "    headers: {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Authorization\": `Bearer \"\"\"+OpenAIKey+\"\"\"`\n",
        "    },\n",
        "    body: `{ \"input\": \"${text}\", \"model\": \"text-embedding-ada-002\" }`\n",
        "  })\n",
        "  let data = await response.json();\n",
        "  return data.data[0].embedding;\n",
        "}\n",
        "\n",
        "const similarIssuesField = ({ parent: { id },dql }) => findSimilarIssuesById(id, 5,dql);\n",
        "\n",
        "async function getSimilarIssues({ args, dql }) {\n",
        "  const description = args.description;\n",
        "  const limit = args.first;\n",
        "  const similar = await findSimilarIssues(description, limit, dql);\n",
        "  return similar;\n",
        "}\n",
        "async function getSimilarIssuesById({ args, dql }) {\n",
        "  //const description = args.description;\n",
        "  const limit = args.first;\n",
        "  const similar = await findSimilarIssuesById(args.uid, limit, dql);\n",
        "  return similar;\n",
        "}\n",
        "\n",
        "async function findSimilarIssuesById(uid, limit, dql) {\n",
        "  console.log(\"ID\");\n",
        "  console.log(uid)\n",
        "  //id = id.substring(2); // remove the leading 0x\n",
        "  let qdID = BigInt(uid).toString(); // convert hex to decimal\n",
        "  console.log(qdID);\n",
        "  //const v1 = await embedding(description);\n",
        "  const issues = await searchSimilarityByID(qdID, \"Issue\", limit);\n",
        "  //const issues = await searchSimilarity(v1, \"Issue\", limit);\n",
        "\n",
        "  const ids = issues.map((issue) => '0x' + BigInt(issue.id).toString(16));\n",
        "  const scores = {};\n",
        "  issues.forEach((issue) => {\n",
        "    scores['0x' + BigInt(issue.id).toString(16)] = issue.score;\n",
        "  });\n",
        "\n",
        "  const query = `{\n",
        "    issues(func: uid(${ids})) {\n",
        "      id: uid\n",
        "      name: Issue.name\n",
        "      description: Issue.description\n",
        "      solution: Issue.solution\n",
        "      oilRig: Issue.oilRig {\n",
        "        name: OilRig.name\n",
        "      }\n",
        "    }\n",
        "  }`;\n",
        "  console.log(\"SimilarIssues Debug\")\n",
        "  console.log(query)\n",
        "  const results = await dql.query(query);\n",
        "  console.log(\"SimilarIssues Debug\")\n",
        "  console.log(results)\n",
        "  results.data.issues.forEach((issue) => {\n",
        "    issue.score = scores[issue.id];\n",
        "  });\n",
        "\n",
        "  return results.data.issues;\n",
        "}\n",
        "\n",
        "async function addIssueWebhook({ event, dql, graphql, authHeader }) {\n",
        "  var rdfs = \"\";\n",
        "  for (let i = 0; i < event.add.rootUIDs.length; ++i) {\n",
        "    console.log(`adding embedding for Issue ${event.add.rootUIDs[i]} ${event.add.input[i]['name']}`);\n",
        "    const uid = event.add.rootUIDs[i];\n",
        "    const v1 = await embedding(event.add.input[i].description);\n",
        "    await saveVector(\"Issue\", uid, v1);\n",
        "  similarCategories = await searchSimilarity(v1,\"Issue\",10);\n",
        "    if  (event.add.input[i]['issue'] == undefined) { // if the project is added without category\n",
        "      let issue=\"\";\n",
        "      let max = 0.0;\n",
        "      let similarityMutation = \"\";\n",
        "      for (let c of similarIssues ) {\n",
        "          cuid = \"0x\"+BigInt(c.id).toString(16);\n",
        "          similarityMutation += `<${uid}>  <similarity> <${cuid}> (cosine=${c.score}) .\n",
        "         `;\n",
        "          if (c.score > max) {\n",
        "            issue = cuid;\n",
        "            max = c.score;\n",
        "          }\n",
        "\n",
        "      }\n",
        "      console.log(`set closest issue to ${issue}`)\n",
        "      rdfs += `${similarityMutation}\n",
        "              <${uid}> <Issue> <${issue}> .\n",
        "                `;\n",
        "    } else {\n",
        "      rdfs += `<${uid}>  <embedding> \"${serialized}\" .\n",
        "                `;\n",
        "    }\n",
        "  }\n",
        "  await mutateRDF(dql,rdfs);\n",
        "}\n",
        "\n",
        "async function addOilRigWebhook({ event, dql, graphql, authHeader }) {\n",
        "  var rdfs = \"\";\n",
        "  console.log(\"Whole Event\");\n",
        "  console.log(JSON.stringify(event, null, 2));\n",
        "\n",
        "  for (let i = 0; i < event.add.rootUIDs.length; ++i) {\n",
        "    const oilRigUID = event.add.rootUIDs[i];\n",
        "    console.log(\"Rig UID\")\n",
        "    console.log(oilRigUID)\n",
        "    // Query for the oil rig and retrieve the UIDs of its issues\n",
        "    const query = `query MyQuery {\n",
        "  getOilRig(id: \"${oilRigUID}\") {\n",
        "    issues {\n",
        "      id\n",
        "    }\n",
        "  }\n",
        "}`;\n",
        "  console.log(query)\n",
        "    const results = await graphql(query);\n",
        "    console.log(\"queryResults\")\n",
        "    console.log(JSON.stringify(results));\n",
        "    const issues = results.data.getOilRig.issues;\n",
        "\n",
        "    if (issues && issues.length > 0) {\n",
        "      console.log(\"ISSUES\");\n",
        "      console.log(issues);\n",
        "      for (let j = 0; j < issues.length; j++) {\n",
        "        const issue = issues[j];\n",
        "        const issueUID = issue.id;\n",
        "        console.log(issueUID);\n",
        "        console.log(`Adding embedding for Issue ${issueUID}`);\n",
        "        const v1 = await embedding(event.add.input[i].issues[j].description);\n",
        "        await saveVector(\"Issue\", issueUID, v1);\n",
        "\n",
        "        rdfs += `<${issueUID}> <issueOf> <${oilRigUID}> .\n",
        "                  `;\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "\n",
        "  await mutateRDF(dql, rdfs);\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "self.addWebHookResolvers({\n",
        "  \"Issue.add\": addIssueWebhook,\n",
        "  \"OilRig.add\": addOilRigWebhook\n",
        "});\n",
        "\n",
        "self.addGraphQLResolvers({\n",
        "  \"Query.getSimilarIssues\": getSimilarIssues,\n",
        "  \"Query.getSimilarIssuesById\": getSimilarIssuesById,\n",
        "  \"Issue.similarIssues\": similarIssuesField,\n",
        "});\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "encoded = base64.b64encode(script.encode('utf-8'))\n",
        "\n",
        "\n",
        "mutation = \"\"\"\n",
        "mutation ($deploymentID: ID!, $tenantID: Int!,$lambdaScript: String! ){\n",
        "  updateLambda(input: { deploymentID: $deploymentID, tenantID: $tenantID, lambdaScript: $lambdaScript})\n",
        "}\n",
        "\"\"\"\n",
        "variables = {\n",
        "    \"deploymentID\":deploymentID,\n",
        "    \"tenantID\":0,\n",
        "    \"lambdaScript\": str(encoded, \"utf-8\")\n",
        "}\n",
        "deployment_status = gql_cloud_client.execute(query=mutation, variables=variables,headers=cerebro_headers)\n",
        "\n",
        "\n",
        "print(deployment_status)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UvkyYXf3VTWj",
        "outputId": "596321f5-e60b-4816-95df-04fe3a9f63c6"
      },
      "outputs": [],
      "source": [
        "# add predicates to Dgraph type schema\n",
        "# we are using those 2 predicates in the lambda logic.\n",
        "# if your cluster is in strict mode we must delcare the predicates before using them\n",
        "\n",
        "dqlschema = \"\"\"\n",
        "  embedding: string .\n",
        "  similarity: [uid] .\n",
        "\"\"\"\n",
        "op = pydgraph.Operation(schema=dqlschema)\n",
        "client.alter(op)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dabRCe1Enm1h"
      },
      "source": [
        "# Check data was classified via LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pb5cT-oYZCh",
        "outputId": "14c7d6dc-247e-46c4-8a5d-2fe4723b149f"
      },
      "outputs": [],
      "source": [
        "# Verify projects were categorized into recommended (fuzzy) categories !\n",
        "queryProjects = \"\"\"\n",
        "query queryProjects {\n",
        "    queryProject(first:100) {\n",
        "        id title\n",
        "        category {\n",
        "            name\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "data = gql_client.execute(query=queryProjects)\n",
        "\n",
        "print(json.dumps(data['data']['queryProject'], indent=2))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Td6EPN4FnxZX"
      },
      "source": [
        "# Visualize some graph data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJZbTLhEcS2c"
      },
      "outputs": [],
      "source": [
        "import ipycytoscape\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "graph_data = {\"nodes\": [], \"edges\": []}\n",
        "for p in data:\n",
        "    graph_data['nodes'].append({\"data\": {\"id\": p['uid'], \"label\": p['title'], \"type\": p['dgraph.type'][0]}, \"classes\": p['dgraph.type'][0]})\n",
        "\n",
        "\n",
        "cyto_styles = [\n",
        "    {'selector': 'node[type = \"Project\"]', 'style': {\n",
        "        'font-family': 'helvetica',\n",
        "        'font-size': '6px',\n",
        "        'label': 'data(label)',\n",
        "        'background-color': 'blue'}}\n",
        "]\n",
        "\n",
        "cytoscapeobj = ipycytoscape.CytoscapeWidget()\n",
        "cytoscapeobj.graph.add_graph_from_json(graph_data)\n",
        "cytoscapeobj.set_style(cyto_styles)\n",
        "cytoscapeobj.set_layout(name='cola', animate = True, nodeSpacing=10, edgeLengthVal=45, maxSimulationTime= 1500)\n",
        "\n",
        "#display\n",
        "cytoscapeobj"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9k8FiQMMn7et"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QVAOTnOMZGtN"
      },
      "source": [
        "## overview\n",
        "This Python notebook sets up Dgraph to integrate graph data, LLM-based text analysis, and Vector-DB based fuzzy links into one overall Graph, and expose it via GraphQL.\n",
        "\n",
        "Once this is run, GraphQL inserts and queries will transparently work to store all data, query all relationships, and knit fuzzy, AI-based links among data with actual data linkages from source systems.\n",
        "\n",
        "The presented Python notebook code exhibits an advanced usage of Dgraph as a graph database, in combination with Qdrant as a vector database and OpenAI as a tool for generating embeddings. In this case, the graph database Dgraph is used for managing structured data, while the vector database Qdrant is used for managing and searching through high-dimensional data points, namely the embeddings generated by OpenAI.\n",
        "\n",
        "The architecture suggested by this code leverages Dgraph's lambda features, which provide the capability to execute JavaScript functions in response to certain events, such as additions, updates, and deletions of data. In the current context, these JavaScript functions are used to manage the interactions between Dgraph, Qdrant, and OpenAI.\n",
        "\n",
        "When new Oil Rigs/Issues are added in Dgraph, the lambda functions respectively are triggered. These functions call out to OpenAI's API to generate an embedding (vector) for each newly added entity, based on the text in the entity. These embedding vectors are then stored in Qdrant, a vector database.\n",
        "\n",
        "to: ChatGPT.AI Assistant<|im_sep|>To understand the benefits of using Dgraph and Lambda functions for working with Large Language Models (LLMs) and vector databases, let's delve deeper into the structure and functionality of the presented code.\n",
        "\n",
        "--\n",
        "\n",
        "\n",
        "\n",
        "## Here are the key components of the code:\n",
        "\n",
        "Dgraph: Dgraph is a distributed, transactional, open-source graph database built to provide Google-grade scale and speed, enabling the user to ask complex queries and receive responses in real time. Its horizontal scalability and distributed architecture make it an excellent choice for applications with heavy data and query loads. Dgraph uses GraphQL to both navigate graphs (networks) of data, and also to integrate multiple data sources into a single API.\n",
        "\n",
        "Lambda Functions in Dgraph: Lambda functions are JavaScript functions that execute custom logic on the database side in response to GraphQL mutations and queries. In this case, the lambda functions search for similar vector representations of objects in the database. The Lambda feature allows more complex functionality to appear as part of a GraphQL API.\n",
        "\n",
        "OpenAI API: OpenAI's API is used to generate embeddings for text. The 'text-embedding-ada-002' model transforms a text into a vector representation that captures its semantic content. The embedding is then saved in the Qdrant database and associated with the Dgraph node with the original text.\n",
        "\n",
        "Qdrant Vector Database: Qdrant is a vector similarity search engine with extended functionality for manipulating vector collections. It is used to store and search for vector representations of objects (like projects or categories) to determine similarity between different entities.\n",
        "\n",
        "## Now let's delve into how the system works as a whole:\n",
        "\n",
        "\n",
        "\n",
        "Finding similar items: When a GraphQL request includes links to similar objects, a Lambda function is invoked to determine what is similar or related. The function generates an embedding for the input object text using the OpenAI API and then calls out to Qdrant to find similar items.\n",
        "\n",
        "\n",
        "## Pulling it all together\n",
        "In conclusion, this integration leverages the power of Large Language Models and vector databases with Dgraph. By associating semantic embeddings with graph nodes, we can perform similarity searches and automatically categorize entities. Because Dgraph exposes data via GraphQL, the process is transparent to users - they simply query the graph, and some of the \"edgs\" are actually AI generated similarity links. Dgraph itself internally stores all non-fuzzy relations and data values, allowing massive scale and fast query, together with AI, LLMs and similarity metrics.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tkyNShzbZaam"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
