{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset prep for RAG on Dgraph blog post\n",
    "\n",
    "We decided to use the dataset from the article [RAG with a Graph database](https://cookbook.openai.com/examples/rag_with_graph_db).\n",
    "\n",
    "\n",
    "RDF is a powerful notation for knowledge graph. It describes information in triples of the form Subject - Predicate - Object (S-P-O).\n",
    "\n",
    "The original dataset is in JSON format and is 2.7Mb. We have generated an RDF file with the exact same information. The RDF file is only 361 Kb! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# RDF subjects have no spaces\n",
    "def clean_name(name):\n",
    "    clean_string = [s for s in name if s.isalnum()]\n",
    "    return \"\".join(clean_string)\n",
    "def clean_text(text):\n",
    "    return text.replace('\"','\\\\\"').replace('\\n','').replace('\\r','').replace('\\t','')\n",
    "\n",
    "def toRDF(df):\n",
    "    nquad_list = []\n",
    "    # correct the material entity type which is not in the original dataset\n",
    "    for idx,row in df.iterrows():\n",
    "        if row[\"relationship\"] == \"hasMaterial\":\n",
    "            df.at[idx,\"entity_type\"] = \"material\"\n",
    "    # Generates Product data\n",
    "    products = df[['product', 'product_id','TITLE']].drop_duplicates()\n",
    "    for idx,row in products.iterrows():\n",
    "        nquad_list.append(f'<_:P_{row[\"product_id\"]}> <Product.Title> \"{clean_text(row[\"TITLE\"])}\" .')\n",
    "        nquad_list.append(f'<_:P_{row[\"product_id\"]}> <dgraph.type> \"Product\" .')\n",
    "        nquad_list.append(f'<_:P_{row[\"product_id\"]}> <Product.Name> \"{clean_text(row[\"product\"])}\" .')\n",
    "        nquad_list.append(f'<_:P_{row[\"product_id\"]}> <Product.ID> \"{row[\"product_id\"]}\" .')\n",
    "    # Generate all other entities\n",
    "    types = df[['entity_type','entity_value']].drop_duplicates()\n",
    "    for idx,row in types.iterrows():\n",
    "        nquad_list.append(f'<_:{row[\"entity_type\"]}_{clean_name(row[\"entity_value\"])}> <dgraph.type> \"{row[\"entity_type\"]}\" .')\n",
    "        nquad_list.append(f'<_:{row[\"entity_type\"]}_{clean_name(row[\"entity_value\"])}> <{row[\"entity_type\"]}.Value> \"{clean_text(row[\"entity_value\"])}\" .')\n",
    "    \n",
    "    # generate relations\n",
    "    for idx,row in df.iterrows():\n",
    "        nquad_list.append(f'<_:P_{row[\"product_id\"]}> <Product.{row[\"entity_type\"]}> <_:{row[\"entity_type\"]}_{clean_name(row[\"entity_value\"])}> .')\n",
    "    # nquad_list = [ f'<P_{row[\"product_id\"]}> <TITLE> \"{row[\"TITLE\"]}\" .' for idx,row in products.iterrows()]\n",
    "    return nquad_list\n",
    "\n",
    "# Loading a json dataset from a file\n",
    "file_path = \"data/amazon_product_kg.json\"\n",
    "output_path =\"data/products.rdf\"\n",
    "df = pd.read_json(file_path)\n",
    "with open(output_path,'w') as filehandle:\n",
    "    filehandle.write(\"\\n\".join(toRDF(df)))\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
